#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ BOT SHA-256 - AI-Powered Social Media Automation
Features: AI Performance Analysis, Timezone Optimization, Smart Targeting
Open Source Project - MIT License
"""

import os
import json
import random
import logging
import requests
import time
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple
import tweepy
import praw
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor
import threading
import uuid
import sqlite3
from flask import Flask, render_template, jsonify
import pytz
import numpy as np
from collections import defaultdict
import telegram
from telegram.ext import Application, MessageHandler, filters

# Enhanced logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/voltagegpu_enhanced.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class PerformanceAnalyzer:
    """AI-powered performance analysis and optimization"""
    
    def __init__(self):
        self.db_path = 'performance_analytics.db'
        self.init_database()
        self.performance_weights = {
            'engagement_rate': 0.4,
            'click_rate': 0.3,
            'conversion_rate': 0.2,
            'reach': 0.1
        }
        
    def init_database(self):
        """Initialize performance tracking database"""
        # Fix SQLite datetime adapter deprecation warning
        sqlite3.register_adapter(datetime, lambda dt: dt.isoformat())
        sqlite3.register_converter("TIMESTAMP", lambda b: datetime.fromisoformat(b.decode()))
        
        conn = sqlite3.connect(self.db_path, detect_types=sqlite3.PARSE_DECLTYPES)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS post_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                platform TEXT NOT NULL,
                region TEXT NOT NULL,
                language TEXT NOT NULL,
                content_type TEXT NOT NULL,
                post_time TIMESTAMP NOT NULL,
                timezone TEXT NOT NULL,
                engagement_count INTEGER DEFAULT 0,
                click_count INTEGER DEFAULT 0,
                conversion_count INTEGER DEFAULT 0,
                reach_count INTEGER DEFAULT 0,
                content_hash TEXT NOT NULL,
                subreddit TEXT,
                hashtags TEXT,
                performance_score REAL DEFAULT 0.0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS optimal_times (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                platform TEXT NOT NULL,
                region TEXT NOT NULL,
                language TEXT NOT NULL,
                hour INTEGER NOT NULL,
                day_of_week INTEGER NOT NULL,
                avg_performance REAL DEFAULT 0.0,
                post_count INTEGER DEFAULT 0,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        
    def record_post_performance(self, platform: str, region: str, language: str, 
                              content_type: str, post_time: datetime, timezone_str: str,
                              content_hash: str, subreddit: str = None, hashtags: str = None):
        """Record a new post for performance tracking"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO post_performance 
            (platform, region, language, content_type, post_time, timezone, content_hash, subreddit, hashtags)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (platform, region, language, content_type, post_time, timezone_str, content_hash, subreddit, hashtags))
        
        conn.commit()
        conn.close()
        
    def update_performance_metrics(self, content_hash: str, engagement: int = 0, 
                                 clicks: int = 0, conversions: int = 0, reach: int = 0):
        """Update performance metrics for a post"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE post_performance 
            SET engagement_count = ?, click_count = ?, conversion_count = ?, reach_count = ?
            WHERE content_hash = ?
        ''', (engagement, clicks, conversions, reach, content_hash))
        
        # Calculate performance score
        cursor.execute('SELECT * FROM post_performance WHERE content_hash = ?', (content_hash,))
        post = cursor.fetchone()
        
        if post:
            # Calculate weighted performance score
            engagement_rate = engagement / max(reach, 1)
            click_rate = clicks / max(engagement, 1)
            conversion_rate = conversions / max(clicks, 1)
            
            score = (
                engagement_rate * self.performance_weights['engagement_rate'] +
                click_rate * self.performance_weights['click_rate'] +
                conversion_rate * self.performance_weights['conversion_rate'] +
                min(reach / 1000, 1.0) * self.performance_weights['reach']
            )
            
            cursor.execute('UPDATE post_performance SET performance_score = ? WHERE content_hash = ?', 
                         (score, content_hash))
        
        conn.commit()
        conn.close()
        
    def get_optimal_posting_time(self, platform: str, region: str, language: str) -> Tuple[int, float]:
        """Get optimal posting hour for platform/region/language combination"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get historical performance by hour
        cursor.execute('''
            SELECT strftime('%H', post_time) as hour, AVG(performance_score) as avg_score, COUNT(*) as count
            FROM post_performance 
            WHERE platform = ? AND region = ? AND language = ?
            AND performance_score > 0
            GROUP BY hour
            HAVING count >= 3
            ORDER BY avg_score DESC
        ''', (platform, region, language))
        
        results = cursor.fetchall()
        conn.close()
        
        if results:
            best_hour, best_score, _ = results[0]
            return int(best_hour), float(best_score)
        
        # Fallback to general optimal times
        optimal_defaults = {
            'twitter': {'US': 14, 'EU': 12, 'ASIA': 9, 'LATAM': 16},
            'reddit': {'US': 15, 'EU': 13, 'ASIA': 10, 'LATAM': 17},
            'telegram': {'US': 13, 'EU': 11, 'ASIA': 8, 'LATAM': 15}
        }
        
        return optimal_defaults.get(platform, {}).get(region, 12), 0.0
        
    def analyze_content_performance(self, platform: str, region: str, language: str) -> Dict:
        """Analyze what content performs best"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT content_type, AVG(performance_score) as avg_score, COUNT(*) as count
            FROM post_performance 
            WHERE platform = ? AND region = ? AND language = ?
            AND performance_score > 0
            GROUP BY content_type
            ORDER BY avg_score DESC
        ''', (platform, region, language))
        
        results = cursor.fetchall()
        conn.close()
        
        analysis = {
            'best_content_type': results[0][0] if results else 'gpu_deals',
            'performance_by_type': {row[0]: row[1] for row in results},
            'recommendations': []
        }
        
        if results:
            best_type, best_score, _ = results[0]
            analysis['recommendations'].append(f"Focus on {best_type} content (score: {best_score:.3f})")
            
        return analysis

class TimezoneOptimizer:
    """Optimizes posting times based on target regions and timezones"""
    
    def __init__(self):
        self.timezone_mapping = {
            'US_EAST': 'America/New_York',
            'US_CENTRAL': 'America/Chicago', 
            'US_WEST': 'America/Los_Angeles',
            'INDIA': 'Asia/Kolkata',
            'CHINA': 'Asia/Shanghai',
            'BRAZIL': 'America/Sao_Paulo',
            'EU_WEST': 'Europe/London',
            'EU_CENTRAL': 'Europe/Berlin',
            'AUSTRALIA': 'Australia/Sydney',
            'JAPAN': 'Asia/Tokyo'
        }
        
        self.peak_hours = {
            'US_EAST': [13, 14, 15, 16, 17, 18, 19, 20],
            'US_CENTRAL': [12, 13, 14, 15, 16, 17, 18, 19],
            'US_WEST': [10, 11, 12, 13, 14, 15, 16, 17],
            'INDIA': [9, 10, 11, 18, 19, 20, 21, 22],
            'CHINA': [8, 9, 10, 19, 20, 21, 22, 23],
            'BRAZIL': [11, 12, 13, 18, 19, 20, 21, 22],
            'EU_WEST': [8, 9, 12, 13, 17, 18, 19, 20],
            'EU_CENTRAL': [9, 10, 13, 14, 18, 19, 20, 21],
            'AUSTRALIA': [7, 8, 9, 17, 18, 19, 20, 21],
            'JAPAN': [8, 9, 10, 19, 20, 21, 22, 23]
        }
        
        self.language_mapping = {
            'US_EAST': 'en',
            'US_CENTRAL': 'en',
            'US_WEST': 'en',
            'INDIA': 'en',
            'CHINA': 'zh',
            'BRAZIL': 'pt',
            'EU_WEST': 'en',
            'EU_CENTRAL': 'de',
            'AUSTRALIA': 'en',
            'JAPAN': 'ja'
        }
        
    def get_current_optimal_region(self) -> Tuple[str, str, str]:
        """Get the currently optimal region to target based on time"""
        utc_now = datetime.now(timezone.utc)
        
        best_region = None
        best_score = 0
        
        for region, tz_name in self.timezone_mapping.items():
            try:
                tz = pytz.timezone(tz_name)
                local_time = utc_now.astimezone(tz)
                current_hour = local_time.hour
                
                # Calculate score based on peak hours
                peak_hours = self.peak_hours.get(region, [])
                if current_hour in peak_hours:
                    # Higher score for peak hours
                    score = 10 + (len(peak_hours) - peak_hours.index(current_hour))
                else:
                    # Lower score for off-peak hours
                    score = max(0, 5 - min(abs(current_hour - h) for h in peak_hours))
                
                if score > best_score:
                    best_score = score
                    best_region = region
                    
            except Exception as e:
                logging.warning(f"Timezone calculation error for {region}: {e}")
                continue
        
        if not best_region:
            best_region = 'US_EAST'  # Fallback
            
        language = self.language_mapping.get(best_region, 'en')
        timezone_name = self.timezone_mapping.get(best_region, 'America/New_York')
        
        return best_region, language, timezone_name
        
    def is_peak_time(self, region: str) -> bool:
        """Check if current time is peak time for region"""
        try:
            tz = pytz.timezone(self.timezone_mapping[region])
            local_time = datetime.now(timezone.utc).astimezone(tz)
            return local_time.hour in self.peak_hours.get(region, [])
        except:
            return False

class SmartRedditTargeter:
    """Intelligent Reddit subreddit targeting with rule learning and adaptation"""
    
    def __init__(self):
        self.failed_subreddits = {}  # Track failed attempts and reasons
        self.subreddit_rules = {}    # Learn subreddit-specific rules
        self.title_patterns = {}     # Learn successful title patterns
        self.subreddit_mapping = {
            'US_EAST': {
                'en': [
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 10},
                    {'name': 'DeepLearning', 'flair': 'Discussion', 'priority': 9},
                    {'name': 'artificial', 'flair': None, 'priority': 8},
                    {'name': 'LocalLLaMA', 'flair': 'Resource', 'priority': 10},
                    {'name': 'GPURental', 'flair': None, 'priority': 10},
                    {'name': 'CloudComputing', 'flair': None, 'priority': 7}
                ]
            },
            'US_CENTRAL': {
                'en': [
                    {'name': 'programming', 'flair': None, 'priority': 8},
                    {'name': 'compsci', 'flair': 'Discussion', 'priority': 7},
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                    {'name': 'ArtificialIntelligence', 'flair': 'News', 'priority': 8}
                ]
            },
            'US_WEST': {
                'en': [
                    {'name': 'startups', 'flair': None, 'priority': 8},
                    {'name': 'entrepreneur', 'flair': None, 'priority': 7},
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                    {'name': 'artificial', 'flair': None, 'priority': 8}
                ]
            },
            'INDIA': {
                'en': [
                    {'name': 'developersIndia', 'flair': 'Resource', 'priority': 10},
                    {'name': 'india', 'flair': 'Technology', 'priority': 8},
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                    {'name': 'artificial', 'flair': None, 'priority': 7}
                ]
            },
            'CHINA': {
                'zh': [
                    {'name': 'China_irl', 'flair': None, 'priority': 6},
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 8}
                ],
                'en': [
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                    {'name': 'artificial', 'flair': None, 'priority': 8}
                ]
            },
            'BRAZIL': {
                'pt': [
                    {'name': 'brasil', 'flair': 'Tecnologia', 'priority': 8},
                    {'name': 'programacao', 'flair': None, 'priority': 7}
                ],
                'en': [
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9}
                ]
            },
            'EU_WEST': {
                'en': [
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 10},
                    {'name': 'artificial', 'flair': None, 'priority': 8},
                    {'name': 'unitedkingdom', 'flair': 'Technology', 'priority': 7}
                ]
            },
            'EU_CENTRAL': {
                'de': [
                    {'name': 'de', 'flair': 'Technologie', 'priority': 7},
                    {'name': 'germany', 'flair': 'Technology', 'priority': 6}
                ],
                'en': [
                    {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                    {'name': 'artificial', 'flair': None, 'priority': 8}
                ]
            }
        }
        
    def learn_from_failure(self, subreddit_name: str, error_message: str, title: str):
        """Advanced learning from failed posts to avoid future mistakes"""
        error_lower = error_message.lower()
        
        # Initialize tracking for this subreddit
        if subreddit_name not in self.failed_subreddits:
            self.failed_subreddits[subreddit_name] = []
        if subreddit_name not in self.subreddit_rules:
            self.subreddit_rules[subreddit_name] = {}
        
        # Learn from specific error patterns
        if 'tag' in error_lower or 'flair' in error_lower:
            if '[R]' in error_message or '[N]' in error_message or '[P]' in error_message or '[D]' in error_message:
                self.subreddit_rules[subreddit_name]['requires_title_tag'] = True
                self.subreddit_rules[subreddit_name]['title_tags'] = ['[R]', '[N]', '[P]', '[D]']
                logging.info(f"üß† LEARNED: r/{subreddit_name} requires title tags like [R], [N], [P], [D]")
            
            if 'flair' in error_lower:
                self.subreddit_rules[subreddit_name]['requires_flair'] = True
                logging.info(f"üß† LEARNED: r/{subreddit_name} requires post flair")
        
        # Advanced spam detection learning
        if any(word in error_lower for word in ['spam', 'promotional', 'marketing', 'seo', 'self-promotion']):
            self.subreddit_rules[subreddit_name]['strict_anti_spam'] = True
            self.subreddit_rules[subreddit_name]['no_promotional'] = True
            self.subreddit_rules[subreddit_name]['no_affiliate_links'] = True
            logging.info(f"üß† LEARNED: r/{subreddit_name} has STRICT anti-spam policies")
        
        if 'arxiv' in error_lower and 'body text' in error_lower:
            self.subreddit_rules[subreddit_name]['requires_analysis'] = True
            logging.info(f"üß† LEARNED: r/{subreddit_name} requires detailed analysis, not just links")
        
        if 'low-effort' in error_lower or 'beginner' in error_lower:
            self.subreddit_rules[subreddit_name]['no_low_effort'] = True
            logging.info(f"üß† LEARNED: r/{subreddit_name} doesn't allow low-effort posts")
        
        if 'minimum karma' in error_lower or 'account age' in error_lower:
            self.subreddit_rules[subreddit_name]['karma_requirements'] = True
            logging.info(f"üß† LEARNED: r/{subreddit_name} has karma/age requirements")
        
        # Track failure with enhanced context
        self.failed_subreddits[subreddit_name].append({
            'error': error_message,
            'title': title,
            'timestamp': datetime.now().isoformat(),
            'error_type': self._classify_error(error_message)
        })
        
        # If too many failures, reduce priority or blacklist
        failure_count = len(self.failed_subreddits[subreddit_name])
        if failure_count >= 2:  # More aggressive blacklisting
            logging.warning(f"üö´ BLACKLISTING: r/{subreddit_name} - {failure_count} failures")
            self.subreddit_rules[subreddit_name]['blacklisted'] = True
    
    def _classify_error(self, error_message: str) -> str:
        """Classify the type of error for better learning"""
        error_lower = error_message.lower()
        
        if any(word in error_lower for word in ['spam', 'promotional', 'marketing']):
            return 'spam_violation'
        elif 'flair' in error_lower or 'tag' in error_lower:
            return 'formatting_requirement'
        elif 'karma' in error_lower or 'age' in error_lower:
            return 'account_restriction'
        elif 'low-effort' in error_lower:
            return 'quality_requirement'
        else:
            return 'unknown'
    
    def adapt_title_for_subreddit(self, title: str, subreddit_name: str) -> str:
        """Adapt title based on learned rules"""
        if subreddit_name not in self.subreddit_rules:
            return title
        
        rules = self.subreddit_rules[subreddit_name]
        
        # Add required title tags
        if rules.get('requires_title_tag') and rules.get('title_tags'):
            # Choose appropriate tag based on content
            if 'resource' in title.lower() or 'found' in title.lower():
                tag = '[R]'  # Resource
            elif 'news' in title.lower() or 'announcement' in title.lower():
                tag = '[N]'  # News
            elif 'project' in title.lower():
                tag = '[P]'  # Project
            else:
                tag = '[D]'  # Discussion
            
            if not any(t in title for t in rules['title_tags']):
                title = f"{tag} {title}"
                logging.info(f"üîß ADAPTED: Added tag {tag} for r/{subreddit_name}")
        
        return title
    
    def should_skip_subreddit(self, subreddit_name: str) -> bool:
        """Enhanced subreddit filtering based on learned rules"""
        if subreddit_name not in self.subreddit_rules:
            return False
        
        rules = self.subreddit_rules[subreddit_name]
        
        # Skip if blacklisted
        if rules.get('blacklisted'):
            return True
        
        # Skip if has karma requirements (we can't check this easily)
        if rules.get('karma_requirements'):
            return True
        
        # Skip if has strict anti-spam policies
        if rules.get('strict_anti_spam'):
            return True
        
        # Skip if doesn't allow promotional content
        if rules.get('no_promotional'):
            return True
        
        # Skip if requires detailed analysis (we don't provide that)
        if rules.get('requires_analysis'):
            return True
        
        # Skip if doesn't allow low-effort posts
        if rules.get('no_low_effort'):
            return True
        
        return False
    
    def generate_educational_content(self, subreddit_name: str, offer: Dict = None) -> Tuple[str, str]:
        """Generate educational, non-promotional content for strict subreddits"""
        
        # Educational titles that don't look promotional
        educational_titles = [
            "Analysis: GPU rental market trends and cost optimization strategies",
            "Discussion: Decentralized GPU computing vs traditional cloud providers",
            "Research: Cost-effective GPU access for machine learning projects",
            "Study: Comparing GPU rental platforms for AI development",
            "Analysis: GPU pricing models in cloud computing",
            "Discussion: Affordable GPU access for independent researchers"
        ]
        
        # Educational content that provides value
        educational_content = f"""
I've been researching cost-effective GPU access for machine learning projects and wanted to share some findings with the community.

**Key Observations:**
‚Ä¢ Traditional cloud providers (AWS, GCP, Azure) can be expensive for extended training
‚Ä¢ Decentralized GPU rental platforms are emerging as alternatives
‚Ä¢ Cost savings of 60-80% are possible with careful platform selection
‚Ä¢ Important factors: reliability, uptime, geographic distribution

**Technical Considerations:**
‚Ä¢ Docker container compatibility
‚Ä¢ CUDA version support
‚Ä¢ Network bandwidth for data transfer
‚Ä¢ Storage options and pricing

**Community Question:**
What has been your experience with different GPU rental solutions? Any recommendations for cost-effective options that maintain good reliability?

*Note: This is for educational discussion. I'm not affiliated with any specific platform.*
"""
        
        title = random.choice(educational_titles)
        
        # Add appropriate tags if learned
        if subreddit_name in self.subreddit_rules:
            rules = self.subreddit_rules[subreddit_name]
            if rules.get('requires_title_tag'):
                title = f"[D] {title}"  # Discussion tag
        
        return title, educational_content.strip()
    
    def get_target_subreddits(self, region: str, language: str) -> List[Dict]:
        """Get target subreddits for region and language with intelligent filtering"""
        region_mapping = self.subreddit_mapping.get(region, {})
        subreddits = region_mapping.get(language, [])
        
        # Fallback to English if no language-specific subreddits
        if not subreddits and language != 'en':
            subreddits = region_mapping.get('en', [])
            
        # Global fallback
        if not subreddits:
            subreddits = [
                {'name': 'MachineLearning', 'flair': 'Resource', 'priority': 9},
                {'name': 'artificial', 'flair': None, 'priority': 8}
            ]
        
        # Filter out problematic subreddits based on learned rules
        filtered_subreddits = []
        for sub in subreddits:
            if not self.should_skip_subreddit(sub['name']):
                # Adjust priority based on failure history
                if sub['name'] in self.failed_subreddits:
                    failure_count = len(self.failed_subreddits[sub['name']])
                    sub['priority'] = max(1, sub['priority'] - failure_count)
                filtered_subreddits.append(sub)
            else:
                logging.info(f"üö´ SKIPPING: r/{sub['name']} - learned to avoid")
        
        return sorted(filtered_subreddits, key=lambda x: x['priority'], reverse=True)

class TelegramGroupManager:
    """Manages autonomous Telegram group joining and posting"""
    
    def __init__(self, bot_token: str):
        self.bot_token = bot_token
        self.target_groups = {
            'US_EAST': {
                'en': [
                    '@AIMLCommunity', '@MachineLearningGroup', '@DeepLearningAI',
                    '@GPUTrading', '@CloudComputingGroup'
                ]
            },
            'INDIA': {
                'en': [
                    '@IndianDevelopers', '@AIIndia', '@TechIndia',
                    '@MachineLearningIndia', '@DeepLearningIndia'
                ]
            },
            'CHINA': {
                'zh': [
                    '@AIChina', '@MachineLearningChina', '@TechChina'
                ],
                'en': [
                    '@AIChina_EN', '@MLChina_EN'
                ]
            },
            'BRAZIL': {
                'pt': [
                    '@TechBrasil', '@AIBrasil', '@DesenvolvedoresBR'
                ],
                'en': [
                    '@TechBrazil_EN'
                ]
            },
            'EU_WEST': {
                'en': [
                    '@EuropeTech', '@AIEurope', '@MLEurope'
                ]
            }
        }
        
        self.joined_groups = set()
        self.group_performance = defaultdict(list)
        
    async def find_and_join_groups(self, region: str, language: str):
        """Enhanced group finding and joining with search capabilities"""
        try:
            app = Application.builder().token(self.bot_token).build()
            bot = app.bot
            
            target_groups = self.target_groups.get(region, {}).get(language, [])
            
            # Search keywords for finding groups
            search_keywords = {
                'en': ['AI', 'MachineLearning', 'GPU', 'DeepLearning', 'Tech', 'Programming'],
                'zh': ['‰∫∫Â∑•Êô∫ËÉΩ', 'Êú∫Âô®Â≠¶‰π†', 'GPU', 'Ê∑±Â∫¶Â≠¶‰π†', 'ÁßëÊäÄ'],
                'pt': ['IA', 'MachineLearning', 'GPU', 'Tecnologia', 'Programacao'],
                'de': ['KI', 'MachineLearning', 'GPU', 'Technologie', 'Programmierung']
            }
            
            # Try to access known groups
            for group in target_groups:
                if group not in self.joined_groups:
                    try:
                        # Try to get chat info
                        chat = await bot.get_chat(group)
                        
                        # Check if it's a group/supergroup
                        if chat.type in ['group', 'supergroup']:
                            # Try to get member count (this works if bot has access)
                            try:
                                member_count = await bot.get_chat_member_count(group)
                                if member_count > 10:  # Only join active groups
                                    self.joined_groups.add(group)
                                    logging.info(f"‚úÖ Joined group {group} ({member_count} members) for {region}/{language}")
                                else:
                                    logging.info(f"‚ö†Ô∏è Group {group} too small ({member_count} members)")
                            except:
                                # If we can't get member count, still try to join
                                self.joined_groups.add(group)
                                logging.info(f"‚úÖ Accessed group {group} for {region}/{language}")
                        else:
                            logging.info(f"üì¢ {group} is a channel, will use for posting")
                            self.joined_groups.add(group)
                        
                    except telegram.error.Forbidden:
                        logging.warning(f"üö´ Bot not authorized for {group}")
                    except telegram.error.ChatNotFound:
                        logging.warning(f"‚ùì Group {group} not found or private")
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è Cannot access {group}: {e}")
                        continue
            
            # Try to discover new groups using search (limited by Telegram API)
            await self._discover_public_groups(bot, region, language, search_keywords.get(language, ['AI', 'Tech']))
                        
        except Exception as e:
            logging.error(f"‚ùå Group management error: {e}")
    
    async def _discover_public_groups(self, bot, region: str, language: str, keywords: List[str]):
        """Try to discover public groups (limited by Telegram API restrictions)"""
        try:
            # Note: Telegram Bot API doesn't allow searching for groups directly
            # This is a placeholder for potential future functionality
            # In practice, groups need to be manually added to target_groups
            
            # Alternative: Try common group username patterns
            common_patterns = [
                f"{keyword.lower()}group",
                f"{keyword.lower()}chat", 
                f"{keyword.lower()}community",
                f"{keyword.lower()}{region.lower()}",
                f"{region.lower()}{keyword.lower()}"
            ]
            
            for keyword in keywords[:2]:  # Limit to avoid spam
                for pattern in common_patterns[:2]:  # Limit patterns
                    try:
                        potential_group = f"@{pattern}"
                        if potential_group not in self.joined_groups:
                            chat = await bot.get_chat(potential_group)
                            if chat.type in ['group', 'supergroup']:
                                self.joined_groups.add(potential_group)
                                logging.info(f"üîç DISCOVERED: {potential_group} for {region}/{language}")
                                break  # Don't spam too many discoveries
                    except:
                        continue  # Group doesn't exist or not accessible
                        
        except Exception as e:
            logging.debug(f"Group discovery error: {e}")
    
    def add_discovered_group(self, group_username: str, region: str, language: str):
        """Manually add a discovered group to targets"""
        if region not in self.target_groups:
            self.target_groups[region] = {}
        if language not in self.target_groups[region]:
            self.target_groups[region][language] = []
        
        if group_username not in self.target_groups[region][language]:
            self.target_groups[region][language].append(group_username)
            logging.info(f"‚ûï Added {group_username} to targets for {region}/{language}")
            
    def get_active_groups(self, region: str, language: str) -> List[str]:
        """Get list of active groups for region/language"""
        target_groups = self.target_groups.get(region, {}).get(language, [])
        return [group for group in target_groups if group in self.joined_groups]

class ContentGenerator:
    """Enhanced content generator with multilingual support"""
    
    def __init__(self):
        self.used_content_hashes = set()
        self.multilingual_templates = {
            'en': {
                'twitter': {
                    'gpu_deals': [
                        "üö® GPU DEAL ALERT! üö®\n\nüíª {gpu_count}x {gpu_type} @ ${price}/hr\n‚ö° {savings}% cheaper than AWS\nüåç {location} | {uptime}% uptime\n\nüí∞ Code {affiliate_code} = 5% OFF!\nüîó https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}",
                        "üî• INSANE GPU PRICING! üî•\n\nüñ•Ô∏è {gpu_count}x {gpu_type} for ${price}/hour\nüí∏ Save {savings}% vs traditional cloud\nüìç {location} datacenter | {uptime}% SLA\n\nüéÅ Exclusive: {affiliate_code} for 5% discount\nüöÄ https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ],
                    'affiliate': [
                        "üí∞ PASSIVE INCOME ALERT! üí∞\n\nü§ë GPU referrals = steady cash flow\nüìà 5% commission per rental\nüî• Code {affiliate_code} works globally\n‚ö° 70% cheaper than AWS = easy sells\n\nüí∏ Start earning: https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ]
                }
            },
            'zh': {
                'twitter': {
                    'gpu_deals': [
                        "üö® GPU‰ºòÊÉ†Ë≠¶Êä•ÔºÅüö®\n\nüíª {gpu_count}x {gpu_type} @ ${price}/Â∞èÊó∂\n‚ö° ÊØîAWS‰æøÂÆú{savings}%\nüåç {location} | {uptime}%Ê≠£Â∏∏ËøêË°åÊó∂Èó¥\n\nüí∞ ‰ª£Á†Å {affiliate_code} = 5%ÊäòÊâ£ÔºÅ\nüîó https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ],
                    'affiliate': [
                        "üí∞ Ë¢´Âä®Êî∂ÂÖ•Ë≠¶Êä•ÔºÅüí∞\n\nü§ë GPUÊé®Ëçê = Á®≥ÂÆöÁé∞ÈáëÊµÅ\nüìà ÊØèÊ¨°ÁßüËµÅ5%‰Ω£Èáë\nüî• ‰ª£Á†Å {affiliate_code} ÂÖ®ÁêÉÊúâÊïà\n‚ö° ÊØîAWS‰æøÂÆú70% = ÂÆπÊòìÈîÄÂîÆ\n\nüí∏ ÂºÄÂßãËµöÈí±: https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ]
                }
            },
            'pt': {
                'twitter': {
                    'gpu_deals': [
                        "üö® ALERTA DE OFERTA GPU! üö®\n\nüíª {gpu_count}x {gpu_type} @ ${price}/hora\n‚ö° {savings}% mais barato que AWS\nüåç {location} | {uptime}% uptime\n\nüí∞ C√≥digo {affiliate_code} = 5% OFF!\nüîó https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ],
                    'affiliate': [
                        "üí∞ ALERTA DE RENDA PASSIVA! üí∞\n\nü§ë Refer√™ncias GPU = fluxo de caixa constante\nüìà 5% comiss√£o por aluguel\nüî• C√≥digo {affiliate_code} funciona globalmente\n‚ö° 70% mais barato que AWS = vendas f√°ceis\n\nüí∏ Comece a ganhar: https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ]
                }
            },
            'de': {
                'twitter': {
                    'gpu_deals': [
                        "üö® GPU ANGEBOT ALARM! üö®\n\nüíª {gpu_count}x {gpu_type} @ ${price}/Stunde\n‚ö° {savings}% g√ºnstiger als AWS\nüåç {location} | {uptime}% Verf√ºgbarkeit\n\nüí∞ Code {affiliate_code} = 5% RABATT!\nüîó https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ],
                    'affiliate': [
                        "üí∞ PASSIVES EINKOMMEN ALARM! üí∞\n\nü§ë GPU Empfehlungen = stetiger Cashflow\nüìà 5% Provision pro Miete\nüî• Code {affiliate_code} funktioniert global\n‚ö° 70% g√ºnstiger als AWS = einfache Verk√§ufe\n\nüí∏ Verdienen starten: https://voltagegpu.com/?ref={affiliate_code}\n\n#{hashtag1} #{hashtag2}"
                    ]
                }
            }
        }
        
        # Add telegram templates for each language
        for lang in self.multilingual_templates:
            if 'telegram' not in self.multilingual_templates[lang]:
                self.multilingual_templates[lang]['telegram'] = {
                    'gpu_deals': self.multilingual_templates[lang]['twitter']['gpu_deals'],
                    'affiliate': self.multilingual_templates[lang]['twitter']['affiliate']
                }
        
        self.hashtag_pools = {
            'en': {
                'gpu': ['GPUDeals', 'GPURental', 'CloudGPU', 'AICompute', 'GPUCloud'],
                'ai': ['AI', 'MachineLearning', 'DeepLearning', 'AITraining', 'NeuralNetworks']
            },
            'zh': {
                'gpu': ['GPU‰∫§Êòì', 'GPUÁßüËµÅ', '‰∫ëGPU', 'AIËÆ°ÁÆó', 'GPU‰∫ë'],
                'ai': ['‰∫∫Â∑•Êô∫ËÉΩ', 'Êú∫Âô®Â≠¶‰π†', 'Ê∑±Â∫¶Â≠¶‰π†', 'AIËÆ≠ÁªÉ', 'Á•ûÁªèÁΩëÁªú']
            },
            'pt': {
                'gpu': ['GPUOfertas', 'GPUAluguel', 'GPUNuvem', 'ComputacaoAI', 'NuvemGPU'],
                'ai': ['IA', 'AprendizadoMaquina', 'AprendizadoProfundo', 'TreinamentoIA', 'RedesNeurais']
            },
            'de': {
                'gpu': ['GPUAngebote', 'GPUMiete', 'CloudGPU', 'AICompute', 'GPUCloud'],
                'ai': ['KI', 'MachineLearning', 'DeepLearning', 'AITraining', 'NeuralNetworks']
            }
        }
        
    def generate_unique_content(self, platform: str, content_type: str, language: str = 'en', 
                              offer: Optional[Dict] = None) -> str:
        """Generate unique multilingual content"""
        max_attempts = 10
        
        # Fallback to English if language not supported
        if language not in self.multilingual_templates:
            language = 'en'
            
        for attempt in range(max_attempts):
            try:
                templates = self.multilingual_templates[language][platform][content_type]
                template = random.choice(templates)
                
                variables = self._generate_variables(language, offer)
                content = template.format(**variables)
                
                # Add unique timestamp for Twitter
                if platform == 'twitter':
                    unique_suffix = f"\n\n‚è∞ {datetime.now().strftime('%H:%M')}"
                    if len(content + unique_suffix) <= 280:
                        content += unique_suffix
                
                # Check uniqueness
                content_hash = hashlib.md5(content.encode()).hexdigest()
                if content_hash not in self.used_content_hashes:
                    self.used_content_hashes.add(content_hash)
                    return content
                    
            except Exception as e:
                logging.warning(f"Content generation error: {e}")
                
        # Fallback
        return self._generate_fallback_content(platform, content_type, language, offer)
        
    def _generate_variables(self, language: str, offer: Optional[Dict] = None) -> Dict:
        """Generate variables for content templates"""
        variables = {
            'affiliate_code': os.getenv('AFFILIATE_CODE', 'SHA-256-DEMO'),
        }
        
        # Get hashtags for language
        hashtag_pool = self.hashtag_pools.get(language, self.hashtag_pools['en'])
        variables['hashtag1'] = random.choice(hashtag_pool['gpu'])
        variables['hashtag2'] = random.choice(hashtag_pool['ai'])
        
        if offer:
            variables.update({
                'gpu_count': offer.get('gpu_count', random.randint(4, 16)),
                'gpu_type': offer.get('gpu_type', random.choice(['H100', 'A100', 'RTX4090'])),
                'price': f"{offer.get('price_per_hour', random.uniform(25, 45)):.2f}",
                'location': offer.get('location', random.choice(['Singapore', 'Mumbai', 'Frankfurt'])),
                'uptime': f"{offer.get('uptime', random.uniform(98, 99.9)):.1f}",
                'savings': random.randint(60, 75)
            })
        else:
            variables.update({
                'gpu_count': random.randint(4, 16),
                'gpu_type': random.choice(['H100', 'A100', 'RTX4090']),
                'price': f"{random.uniform(25, 45):.2f}",
                'location': random.choice(['Singapore', 'Mumbai', 'Frankfurt']),
                'uptime': f"{random.uniform(98, 99.9):.1f}",
                'savings': random.randint(60, 75)
            })
            
        return variables
        
    def _generate_fallback_content(self, platform: str, content_type: str, language: str, 
                                 offer: Optional[Dict] = None) -> str:
        """Generate fallback content"""
        unique_id = str(uuid.uuid4())[:8]
        
        fallback_messages = {
            'en': f"üöÄ VoltageGPU - 70% cheaper GPU rentals! Code {os.getenv('AFFILIATE_CODE', 'DEMO')} saves 5% | https://voltagegpu.com | #{unique_id}",
            'zh': f"üöÄ VoltageGPU - GPUÁßüËµÅ‰æøÂÆú70%ÔºÅ‰ª£Á†Å {os.getenv('AFFILIATE_CODE', 'DEMO')} ËäÇÁúÅ5% | https://voltagegpu.com | #{unique_id}",
            'pt': f"üöÄ VoltageGPU - Aluguel de GPU 70% mais barato! C√≥digo {os.getenv('AFFILIATE_CODE', 'DEMO')} economiza 5% | https://voltagegpu.com | #{unique_id}",
            'de': f"üöÄ VoltageGPU - 70% g√ºnstigere GPU-Miete! Code {os.getenv('AFFILIATE_CODE', 'DEMO')} spart 5% | https://voltagegpu.com | #{unique_id}"
        }
        
        return fallback_messages.get(language, fallback_messages['en'])

class AdvancedRateLimitManager:
    """Advanced rate limiting with timezone awareness"""
    
    def __init__(self):
        self.limits = {
            'twitter': {'requests': 0, 'reset_time': datetime.now(), 'max_per_hour': 15, 'failures': 0},
            'telegram': {'requests': 0, 'reset_time': datetime.now(), 'max_per_hour': 30, 'failures': 0},
            'reddit': {'requests': 0, 'reset_time': datetime.now(), 'max_per_hour': 10, 'failures': 0}
        }
        
    def can_post(self, platform: str) -> bool:
        """Check if we can post to platform"""
        now = datetime.now()
        limit_info = self.limits[platform]
        
        if now >= limit_info['reset_time']:
            limit_info['requests'] = 0
            limit_info['reset_time'] = now + timedelta(hours=1)
            
        return limit_info['requests'] < limit_info['max_per_hour']
    
    def record_request(self, platform: str):
        """Record a request for rate limiting"""
        self.limits[platform]['requests'] += 1
        
    def get_wait_time(self, platform: str) -> int:
        """Get wait time until next request allowed"""
        now = datetime.now()
        reset_time = self.limits[platform]['reset_time']
        if now < reset_time:
            return int((reset_time - now).total_seconds())
        return 0

class ConnectionPoolManager:
    """Manages connection pools to prevent timeout issues"""
    
    def __init__(self):
        self.telegram_session = None
        self.session_lock = threading.Lock()
        
    def get_telegram_session(self):
        """Get or create Telegram session with proper connection pooling"""
        with self.session_lock:
            if self.telegram_session is None:
                import telegram
                from telegram.request import HTTPXRequest
                
                # Create session with connection pooling
                request = HTTPXRequest(
                    connection_pool_size=8,
                    pool_timeout=30,
                    read_timeout=30,
                    write_timeout=30
                )
                
                self.telegram_session = telegram.Bot(
                    token=os.getenv('TELEGRAM_BOT_TOKEN'),
                    request=request
                )
                
            return self.telegram_session
    
    def close_connections(self):
        """Close all connections"""
        with self.session_lock:
            if self.telegram_session:
                try:
                    pass  # Telegram bot doesn't need explicit closing
                except:
                    pass
                self.telegram_session = None

class VoltageGPUBotEnhanced:
    """Enhanced VoltageGPU Bot with AI performance analysis and timezone optimization"""
    
    def __init__(self, test_mode=False):
        self.test_mode = test_mode
        
        # Initialize enhanced components
        self.performance_analyzer = PerformanceAnalyzer()
        self.timezone_optimizer = TimezoneOptimizer()
        self.reddit_targeter = SmartRedditTargeter()
        self.content_generator = ContentGenerator()
        self.rate_limiter = AdvancedRateLimitManager()
        self.connection_manager = ConnectionPoolManager()
        
        # Load configuration
        load_dotenv()
        self.affiliate_code = os.getenv('AFFILIATE_CODE', 'SHA-256-DEMO')
        
        # Initialize Telegram group manager
        if os.getenv('TELEGRAM_BOT_TOKEN'):
            self.telegram_group_manager = TelegramGroupManager(os.getenv('TELEGRAM_BOT_TOKEN'))
        else:
            self.telegram_group_manager = None
        
        # Initialize platforms
        self.setup_platforms()
        
        # Statistics
        self.stats = {
            'twitter_posts': 0,
            'telegram_posts': 0,
            'reddit_posts': 0,
            'errors': 0,
            'start_time': datetime.now(),
            'current_region': 'US_EAST',
            'current_language': 'en'
        }
        
    def setup_platforms(self):
        """Setup all platforms with error handling"""
        # Twitter setup
        self.twitter_clients = []
        try:
            if os.getenv('TWITTER_API_KEY'):
                client = tweepy.Client(
                    bearer_token=os.getenv('TWITTER_BEARER_TOKEN'),
                    consumer_key=os.getenv('TWITTER_API_KEY'),
                    consumer_secret=os.getenv('TWITTER_API_SECRET'),
                    access_token=os.getenv('TWITTER_ACCESS_TOKEN'),
                    access_token_secret=os.getenv('TWITTER_ACCESS_SECRET'),
                    wait_on_rate_limit=False
                )
                self.twitter_clients.append({'client': client, 'name': 'Twitter1', 'posts_today': 0})
                logging.info("‚úÖ Twitter Account 1 connected")
            
            if os.getenv('TWITTER_API_KEY_2'):
                client2 = tweepy.Client(
                    bearer_token=os.getenv('TWITTER_BEARER_TOKEN_2'),
                    consumer_key=os.getenv('TWITTER_API_KEY_2'),
                    consumer_secret=os.getenv('TWITTER_API_SECRET_2'),
                    access_token=os.getenv('TWITTER_ACCESS_TOKEN_2'),
                    access_token_secret=os.getenv('TWITTER_ACCESS_SECRET_2'),
                    wait_on_rate_limit=False
                )
                self.twitter_clients.append({'client': client2, 'name': 'Twitter2', 'posts_today': 0})
                logging.info("‚úÖ Twitter Account 2 connected")
                
        except Exception as e:
            logging.error(f"‚ùå Twitter setup failed: {e}")
        
        # Telegram setup
        self.telegram_bot = None
        try:
            if os.getenv('TELEGRAM_BOT_TOKEN'):
                self.telegram_bot = self.connection_manager.get_telegram_session()
                self.telegram_channels = [
                    os.getenv('TELEGRAM_CHANNEL_ID', '@VoltageGPU')
                ]
                logging.info("‚úÖ Telegram connected with connection pooling")
        except Exception as e:
            logging.error(f"‚ùå Telegram setup failed: {e}")
        
        # Reddit setup
        self.reddit_clients = []
        try:
            if os.getenv('REDDIT_CLIENT_ID'):
                reddit = praw.Reddit(
                    client_id=os.getenv('REDDIT_CLIENT_ID'),
                    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),
                    username=os.getenv('REDDIT_USERNAME'),
                    password=os.getenv('REDDIT_PASSWORD'),
                    user_agent='VoltageGPU Bot Enhanced v2.0'
                )
                self.reddit_clients.append({
                    'client': reddit, 
                    'name': os.getenv('REDDIT_USERNAME'),
                    'posts_today': 0
                })
                logging.info(f"‚úÖ Reddit Account 1 ({os.getenv('REDDIT_USERNAME')}) connected")
            
            if os.getenv('REDDIT_CLIENT_ID_2'):
                reddit2 = praw.Reddit(
                    client_id=os.getenv('REDDIT_CLIENT_ID_2'),
                    client_secret=os.getenv('REDDIT_CLIENT_SECRET_2'),
                    username=os.getenv('REDDIT_USERNAME_2'),
                    password=os.getenv('REDDIT_PASSWORD_2'),
                    user_agent='VoltageGPU Bot Enhanced v2.0'
                )
                self.reddit_clients.append({
                    'client': reddit2, 
                    'name': os.getenv('REDDIT_USERNAME_2'),
                    'posts_today': 0
                })
                logging.info(f"‚úÖ Reddit Account 2 ({os.getenv('REDDIT_USERNAME_2')}) connected")
                
        except Exception as e:
            logging.error(f"‚ùå Reddit setup failed: {e}")
    
    def get_gpu_offers(self) -> List[Dict]:
        """Get GPU offers with enhanced error handling"""
        try:
            # Only try API if we have a valid key
            api_key = os.getenv("VOLTAGE_API_KEY")
            if not api_key or api_key == "your_api_key_here":
                logging.info("üîÑ No valid API key, using mock data")
                return self._generate_mock_offers()
            
            headers = {'Authorization': f'Bearer {api_key}'}
            response = requests.get(
                'https://voltagegpu.com/api/pods',
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    offers = data.get('pods', [])
                    if offers:
                        logging.info(f"‚úÖ API: Retrieved {len(offers)} GPU offers")
                        return offers[:3]
                    else:
                        logging.info("üîÑ API returned empty data, using mock")
                        return self._generate_mock_offers()
                except json.JSONDecodeError:
                    logging.warning("‚ö†Ô∏è API returned invalid JSON, using mock data")
                    return self._generate_mock_offers()
            else:
                logging.warning(f"‚ö†Ô∏è API returned status {response.status_code}, using mock data")
                return self._generate_mock_offers()
                
        except requests.exceptions.Timeout:
            logging.warning("‚ö†Ô∏è API timeout, using mock data")
            return self._generate_mock_offers()
        except requests.exceptions.ConnectionError:
            logging.warning("‚ö†Ô∏è API connection error, using mock data")
            return self._generate_mock_offers()
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è API error: {e}, using mock data")
            return self._generate_mock_offers()
    
    def _generate_mock_offers(self) -> List[Dict]:
        """Generate realistic mock GPU offers"""
        return [{
            'gpu_count': random.choice([4, 8, 16]),
            'gpu_type': random.choice(['H100', 'A100', 'RTX4090']),
            'price_per_hour': round(random.uniform(25, 45), 2),
            'location': random.choice(['Singapore', 'Mumbai', 'Frankfurt']),
            'uptime': round(random.uniform(98, 99.9), 1)
        }]
    
    def update_optimal_targeting(self):
        """Update optimal region and language based on current time"""
        region, language, timezone_name = self.timezone_optimizer.get_current_optimal_region()
        
        if region != self.stats['current_region'] or language != self.stats['current_language']:
            logging.info(f"üåç Switching target: {region} ({language}) - Peak time: {self.timezone_optimizer.is_peak_time(region)}")
            self.stats['current_region'] = region
            self.stats['current_language'] = language
            
            # Join relevant Telegram groups for new region
            if self.telegram_group_manager:
                asyncio.run(self.telegram_group_manager.find_and_join_groups(region, language))
    
    def post_twitter(self):
        """Enhanced Twitter posting with AI optimization"""
        if not self.twitter_clients or not self.rate_limiter.can_post('twitter'):
            return
            
        region = self.stats['current_region']
        language = self.stats['current_language']
        
        # Get AI recommendations for content type
        analysis = self.performance_analyzer.analyze_content_performance('twitter', region, language)
        content_type = analysis['best_content_type']
        
        for twitter_data in self.twitter_clients:
            if twitter_data['posts_today'] >= 15:
                continue
                
            try:
                offers = self.get_gpu_offers()
                content = self.content_generator.generate_unique_content(
                    'twitter', content_type, language, offers[0] if offers else None
                )
                
                if self.test_mode:
                    print(f"üê¶ TEST {twitter_data['name']} ({region}/{language}): {content[:100]}...")
                    continue
                
                response = twitter_data['client'].create_tweet(text=content)
                
                # Record performance for AI analysis
                content_hash = hashlib.md5(content.encode()).hexdigest()
                self.performance_analyzer.record_post_performance(
                    'twitter', region, language, content_type, 
                    datetime.now(), self.timezone_optimizer.timezone_mapping[region],
                    content_hash
                )
                
                twitter_data['posts_today'] += 1
                self.stats['twitter_posts'] += 1
                self.rate_limiter.record_request('twitter')
                
                logging.info(f"‚úÖ {twitter_data['name']}: Posted to {region}/{language} ({twitter_data['posts_today']}/15)")
                time.sleep(5)
                
            except Exception as e:
                self.stats['errors'] += 1
                logging.error(f"‚ùå {twitter_data['name']}: {e}")
    
    def post_telegram(self):
        """Enhanced Telegram posting with group targeting"""
        if not self.telegram_bot or not self.rate_limiter.can_post('telegram'):
            return
            
        region = self.stats['current_region']
        language = self.stats['current_language']
        
        try:
            offers = self.get_gpu_offers()
            analysis = self.performance_analyzer.analyze_content_performance('telegram', region, language)
            content_type = analysis['best_content_type']
            
            content = self.content_generator.generate_unique_content(
                'telegram', content_type, language, offers[0] if offers else None
            )
            
            if self.test_mode:
                print(f"üí¨ TEST TELEGRAM ({region}/{language}): {content[:100]}...")
                return
            
            # Get active groups for current region/language
            active_groups = []
            if self.telegram_group_manager:
                active_groups = self.telegram_group_manager.get_active_groups(region, language)
            
            # Fallback to default channels if no groups available
            if not active_groups:
                active_groups = self.telegram_channels
            
            async def send_messages():
                successful_posts = 0
                for channel in active_groups:
                    try:
                        await self.telegram_bot.send_message(
                            chat_id=channel,
                            text=content
                        )
                        successful_posts += 1
                        logging.info(f"‚úÖ Telegram: Posted to {channel} ({region}/{language})")
                        await asyncio.sleep(2)
                        
                    except Exception as e:
                        logging.error(f"‚ùå Telegram {channel}: {e}")
                        continue
                
                return successful_posts
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                successful_posts = loop.run_until_complete(send_messages())
                
                if successful_posts > 0:
                    # Record performance
                    content_hash = hashlib.md5(content.encode()).hexdigest()
                    self.performance_analyzer.record_post_performance(
                        'telegram', region, language, content_type,
                        datetime.now(), self.timezone_optimizer.timezone_mapping[region],
                        content_hash
                    )
                    
                    self.stats['telegram_posts'] += successful_posts
                    self.rate_limiter.record_request('telegram')
                    
            finally:
                loop.close()
                
        except Exception as e:
            self.stats['errors'] += 1
            logging.error(f"‚ùå Telegram: {e}")
    
    def get_subreddit_flairs(self, subreddit):
        """Get available flairs for a subreddit with error handling"""
        try:
            flairs = list(subreddit.flair.link_templates)
            return {flair['text']: flair['id'] for flair in flairs if flair['text']}
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Could not get flairs for r/{subreddit.display_name}: {e}")
            return {}
    
    def smart_reddit_post(self, reddit_data, subreddit_info, title, content, region, language):
        """Smart Reddit posting with enhanced flair handling"""
        subreddit_name = subreddit_info['name']
        start_time = time.time()
        
        try:
            subreddit = reddit_data['client'].subreddit(subreddit_name)
            
            # Get available flairs
            available_flairs = self.get_subreddit_flairs(subreddit)
            
            # Try posting with different flair strategies
            flair_strategies = []
            
            # Strategy 1: Use suggested flair if available
            if subreddit_info.get('flair') and available_flairs:
                suggested_flair = subreddit_info['flair']
                for flair_text, flair_id in available_flairs.items():
                    if suggested_flair.lower() in flair_text.lower() or flair_text.lower() in suggested_flair.lower():
                        flair_strategies.append({'text': flair_text, 'id': flair_id, 'method': 'suggested_match'})
                        break
            
            # Strategy 2: Use common flairs
            common_flairs = ['Resource', 'Discussion', 'News', 'Question', 'Help']
            for common in common_flairs:
                for flair_text, flair_id in available_flairs.items():
                    if common.lower() in flair_text.lower():
                        flair_strategies.append({'text': flair_text, 'id': flair_id, 'method': 'common_match'})
                        break
            
            # Strategy 3: Use first available flair
            if available_flairs:
                first_flair = list(available_flairs.items())[0]
                flair_strategies.append({'text': first_flair[0], 'id': first_flair[1], 'method': 'first_available'})
            
            # Strategy 4: No flair
            flair_strategies.append({'text': None, 'id': None, 'method': 'no_flair'})
            
            # Try each strategy
            for strategy in flair_strategies:
                try:
                    if strategy['text'] and strategy['id']:
                        submission = subreddit.submit(
                            title=title, 
                            selftext=content, 
                            flair_id=strategy['id']
                        )
                        method = strategy['method']
                        flair_used = strategy['text']
                    else:
                        submission = subreddit.submit(title=title, selftext=content)
                        method = 'no_flair'
                        flair_used = None
                    
                    # Success!
                    elapsed = time.time() - start_time
                    
                    # Record performance
                    content_hash = hashlib.md5(content.encode()).hexdigest()
                    self.performance_analyzer.record_post_performance(
                        'reddit', region, language, 'gpu_deals',
                        datetime.now(), self.timezone_optimizer.timezone_mapping[region],
                        content_hash, subreddit_name
                    )
                    
                    reddit_data['posts_today'] += 1
                    self.stats['reddit_posts'] += 1
                    self.rate_limiter.record_request('reddit')
                    
                    flair_msg = f" with flair '{flair_used}'" if flair_used else " without flair"
                    logging.info(f"‚úÖ Reddit r/{subreddit_name}: Posted by {reddit_data['name']} ({region}/{language}){flair_msg} [{method}] ({elapsed:.1f}s)")
                    return True
                    
                except Exception as strategy_error:
                    error_msg = str(strategy_error).lower()
                    if 'flair' in error_msg and strategy['text']:
                        logging.warning(f"‚ö†Ô∏è Flair '{strategy['text']}' failed on r/{subreddit_name}, trying next strategy")
                        continue
                    else:
                        # Non-flair error, stop trying
                        raise strategy_error
            
            return False
            
        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e).lower()
            
            if '403' in str(e) or 'forbidden' in error_msg:
                logging.error(f"‚ùå BANNED from r/{subreddit_name} - {reddit_data['name']} ({elapsed:.1f}s)")
            elif '429' in str(e) or 'rate limit' in error_msg:
                logging.error(f"‚ùå RATE LIMITED on r/{subreddit_name} - {reddit_data['name']} ({elapsed:.1f}s)")
            elif 'flair' in error_msg:
                logging.error(f"‚ùå FLAIR REQUIRED on r/{subreddit_name} but all strategies failed - {reddit_data['name']} ({elapsed:.1f}s)")
            else:
                logging.error(f"‚ùå Reddit r/{subreddit_name}: {e} - {reddit_data['name']} ({elapsed:.1f}s)")
            
            self.stats['errors'] += 1
            return False
    
    def post_reddit(self):
        """Enhanced Reddit posting with smart targeting and better error handling"""
        if not self.reddit_clients or not self.rate_limiter.can_post('reddit'):
            return
            
        region = self.stats['current_region']
        language = self.stats['current_language']
        
        # Get target subreddits for current region/language
        target_subreddits = self.reddit_targeter.get_target_subreddits(region, language)
        
        for reddit_data in self.reddit_clients:
            if reddit_data['posts_today'] >= 5:
                continue
                
            offers = self.get_gpu_offers()
            analysis = self.performance_analyzer.analyze_content_performance('reddit', region, language)
            content_type = analysis['best_content_type']
            
            content = self.content_generator.generate_unique_content(
                'telegram', content_type, language, offers[0] if offers else None
            )
            
            if offers:
                offer = offers[0]
                title = f"Found {offer['gpu_count']}x {offer['gpu_type']} at ${offer['price_per_hour']:.2f}/hour - 70% cheaper than AWS"
            else:
                title = "VoltageGPU: 70% cheaper GPU rentals for AI/ML projects"
            
            if self.test_mode:
                print(f"üìç TEST REDDIT {reddit_data['name']} ({region}/{language}): {title[:50]}...")
                continue
            
            # Try posting to subreddits in priority order with intelligent learning
            success = False
            for subreddit_info in target_subreddits[:3]:  # Try top 3 subreddits
                subreddit_name = subreddit_info['name']
                
                # Check if this subreddit has strict anti-spam policies
                if (subreddit_name in self.reddit_targeter.subreddit_rules and 
                    self.reddit_targeter.subreddit_rules[subreddit_name].get('strict_anti_spam')):
                    # Use educational content for strict subreddits
                    adapted_title, educational_content = self.reddit_targeter.generate_educational_content(
                        subreddit_name, offers[0] if offers else None
                    )
                    logging.info(f"üéì EDUCATIONAL MODE: Using non-promotional content for r/{subreddit_name}")
                else:
                    # Use regular content with title adaptation
                    adapted_title = self.reddit_targeter.adapt_title_for_subreddit(title, subreddit_name)
                    educational_content = content
                
                try:
                    if self.smart_reddit_post(reddit_data, subreddit_info, adapted_title, educational_content, region, language):
                        success = True
                        break
                except Exception as e:
                    # Learn from the failure
                    self.reddit_targeter.learn_from_failure(subreddit_name, str(e), adapted_title)
                    logging.error(f"üß† LEARNING from r/{subreddit_name} failure: {e}")
                
                time.sleep(2)  # Small delay between attempts
            
            if success:
                time.sleep(10)  # Wait between successful posts
            else:
                logging.warning(f"‚ö†Ô∏è Failed to post to any subreddit for {reddit_data['name']} ({region}/{language}) - AI will adapt")
    
    def display_status(self):
        """Display enhanced status with AI insights"""
        now = datetime.now()
        uptime = now - self.stats['start_time']
        uptime_seconds = int(uptime.total_seconds())
        
        region = self.stats['current_region']
        language = self.stats['current_language']
        is_peak = self.timezone_optimizer.is_peak_time(region)
        
        print(f"\rüöÄ VOLTAGEGPU BOT - ENHANCED AI VERSION")
        print(f"üí∞ AFFILIATE CODE: {self.affiliate_code}")
        print(f"‚è∞ {now.strftime('%H:%M:%S')} | Uptime: {uptime_seconds}s")
        print(f"üåç Current Target: {region} ({language}) {'üî• PEAK TIME' if is_peak else '‚è≥ Off-peak'}")
        
        print(f"\nüîó ACCOUNT STATUS:")
        
        for i, twitter_data in enumerate(self.twitter_clients):
            status = "üü¢ ACTIVE" if twitter_data['posts_today'] < 15 else "üü° LIMIT REACHED"
            print(f"   üê¶ {twitter_data['name']}: {status} ({twitter_data['posts_today']}/15 posts)")
        
        if self.telegram_bot:
            groups_count = len(self.telegram_group_manager.joined_groups) if self.telegram_group_manager else 0
            print(f"   üí¨ Telegram: üü¢ ACTIVE ({self.stats['telegram_posts']} posts, {groups_count} groups)")
        else:
            print(f"   üí¨ Telegram: üî¥ DISCONNECTED")
        
        for reddit_data in self.reddit_clients:
            status = "üü¢ HEALTHY" if reddit_data['posts_today'] < 5 else "üü° LIMIT REACHED"
            print(f"   üìç Reddit ({reddit_data['name']}): {status} ({reddit_data['posts_today']} posts)")
        
        print(f"\nüìä TODAY'S POSTS:")
        print(f"   üê¶ Twitter: {self.stats['twitter_posts']}")
        print(f"   üí¨ Telegram: {self.stats['telegram_posts']}")
        print(f"   üìç Reddit: {self.stats['reddit_posts']}")
        print(f"   üìà TOTAL: {self.stats['twitter_posts'] + self.stats['telegram_posts'] + self.stats['reddit_posts']}")
        print(f"   ‚ùå ERRORS: {self.stats['errors']}")
        
        # AI Performance Insights
        try:
            analysis = self.performance_analyzer.analyze_content_performance('twitter', region, language)
            if analysis['recommendations']:
                print(f"\nü§ñ AI INSIGHTS:")
                for rec in analysis['recommendations'][:2]:
                    print(f"   ‚Ä¢ {rec}")
        except:
            pass
        
        print(f"\nüí∞ AFFILIATE CODE: {self.affiliate_code}")
        print("üõë Ctrl+C to stop" + " " * 20, end="")
    
    def run(self):
        """Run the enhanced VoltageGPU bot"""
        if self.test_mode:
            print("üöÄ TEST MODE - VOLTAGEGPU BOT ENHANCED")
            print("=" * 50)
            
            self.update_optimal_targeting()
            self.post_twitter()
            self.post_telegram()
            self.post_reddit()
            
            print("\n‚úÖ Test completed - All enhanced features working")
            return
            
        print("üöÄ LAUNCHING BOT SHA-256 - AI-POWERED AUTOMATION")
        print("=" * 50)
        print(f"üê¶ Twitter: {len(self.twitter_clients)} accounts")
        print(f"üí¨ Telegram: {'‚úÖ' if self.telegram_bot else '‚ùå'}")
        print(f"üìç Reddit: {len(self.reddit_clients)} accounts")
        print(f"ü§ñ AI Performance Analysis: ‚úÖ ENABLED")
        print(f"üåç Timezone Optimization: ‚úÖ ENABLED")
        print(f"üéØ Smart Targeting: ‚úÖ ENABLED")
        print(f"üí∞ Affiliate code: {self.affiliate_code}")
        print()
        
        try:
            while True:
                # Update optimal targeting based on current time
                self.update_optimal_targeting()
                
                # Post to platforms with AI optimization
                self.post_twitter()
                time.sleep(2)
                
                self.post_telegram()
                time.sleep(2)
                
                self.post_reddit()
                time.sleep(2)
                
                # Display enhanced status
                self.display_status()
                
                # Wait 60 seconds between cycles
                time.sleep(60)
                
        except KeyboardInterrupt:
            print("\n\nüõë VoltageGPU Bot Enhanced stopped")
            logging.info("VoltageGPU Bot Enhanced stopped by user")
            self.connection_manager.close_connections()

def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description='üöÄ VoltageGPU Bot - Enhanced AI Version')
    parser.add_argument('--test', action='store_true', help='Test mode (no actual posting)')
    
    args = parser.parse_args()
    
    try:
        bot = VoltageGPUBotEnhanced(test_mode=args.test)
        bot.run()
    except Exception as e:
        logging.error(f"‚ùå Fatal error: {e}")
        return 1
        
    return 0

if __name__ == "__main__":
    exit(main())
